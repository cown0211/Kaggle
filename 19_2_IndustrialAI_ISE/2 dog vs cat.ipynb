{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "프롬프트 환경에서 설치\n",
    "conda create -n iai python=3.6\n",
    "conda activate iai\n",
    "conda install -c conda-forge tensorflow\n",
    "conda install -c conda-forge opencv\n",
    "conda install -c conda-forge matplotlib\n",
    "conda install -c conda-forge tqdm\n",
    "conda install -c contango tflearn\n",
    "conda install jupyter notebook\n",
    "\n",
    "conda activate iai\n",
    "conda install jupyter notebook\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n",
    "\n",
    "# 폴더 경로 설정\n",
    "TRAIN_DIR = 'C:/Users/UN/dog_cat_img/dogs-vs-cats-redux-kernels-edition/train/train'\n",
    "TEST_DIR = 'C:/Users/UN/dog_cat_img/dogs-vs-cats-redux-kernels-edition/test/test'\n",
    "\n",
    "# Convert Image Size\n",
    "IMG_SIZE = 50\n",
    "\n",
    "# Learning Rate\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image 이름으로 라벨링\n",
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3] # 파일명에서 dog, cat 추출\n",
    "    # conversion to one-hot array [cat,dog]\n",
    "    #                            [much cat, no dog]\n",
    "    # cat은 [1,0]으로, dog는 [0,1]로\n",
    "    if word_label == 'cat': return [1,0]\n",
    "    elif word_label == 'dog': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data set 생성 함수\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        #image 이름으로 라벨링\n",
    "        label = label_img(img)\n",
    "        #image 경로 생성\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        #image 읽기\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        #image 사이즈 변환\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(trainig_data)\n",
    "    #jupyter notebook 경로에 저장\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 25000/25000 [00:17<00:00, 1408.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:08<00:00, 1394.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#data set 생성\n",
    "train_data = create_train_data()\n",
    "test_data = process_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1017 11:06:43.610268 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W1017 11:06:43.611235 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W1017 11:06:43.616221 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W1017 11:06:43.619735 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W1017 11:06:43.624700 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W1017 11:06:43.625697 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#학습을 위한 모델 생성 라이브러리 import\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단순 cnn 모델 구성\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 학습\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1017 11:06:48.842268 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1017 11:06:48.845246 11188 deprecation.py:506] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1017 11:06:48.845246 11188 deprecation.py:323] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "W1017 11:06:48.859199 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\conv.py:552: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1017 11:06:48.916075 11188 deprecation.py:506] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1017 11:06:48.931033 11188 deprecation.py:506] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1017 11:06:48.955003 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W1017 11:06:48.960986 11188 deprecation.py:506] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1017 11:06:49.011819 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W1017 11:06:49.043931 11188 deprecation.py:323] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1017 11:06:49.281357 11188 deprecation_wrapper.py:119] From C:\\Users\\UN\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#심층 cnn 모델 형성\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1148  | total loss: 0.43131 | time: 27.972s\n",
      "| Adam | epoch: 003 | loss: 0.43131 - acc: 0.7992 -- iter: 24448/24500\n",
      "Training Step: 1149  | total loss: 0.43468 | time: 29.040s\n",
      "| Adam | epoch: 003 | loss: 0.43468 - acc: 0.8037 | val_loss: 0.40297 - val_acc: 0.8140 -- iter: 24500/24500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#model 학습\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#지정한 모델명으로 모델 저장\n",
    "#model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot 생성 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#test_data = process_test_data()\n",
    "#test_data = np.load('test_data.npy')\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "for num,data in enumerate(test_data[:12]):\n",
    "    # cat: [1,0]\n",
    "    # dog: [0,1]\n",
    "    \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,4,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 1: str_label='Dog'\n",
    "    else: str_label='Cat'\n",
    "        \n",
    "    y.imshow(orig,cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 12500/12500 [00:18<00:00, 693.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#예측값 csv 저장\n",
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('submission_file.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log파일을 이용한 tensorboard, anaconda prompt에 입력\n",
    "#tensorboard --logdir=\"C:/Users/UN/log\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
